{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name\n",
    "\n",
    "Yuting Kou, Yizhou Wang, Yiming Xu, Ziyi Zhou\n",
    "\n",
    "## Content\n",
    "\n",
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from autograd import numpy as np\n",
    "\n",
    "from src.Inference import Inference\n",
    "from src.Subspace import Subspace\n",
    "from src.model import Model\n",
    "from src.util import hidecode\n",
    "# hidecode()            % --------- remember to remove comments after finishing all the code. This function can simplify the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(r'.\\example\\data.npy')\n",
    "x, y = data[:, 0], data[:, 1]\n",
    "\n",
    "alpha = 1\n",
    "c = 0\n",
    "h = lambda x: np.exp(-alpha * (x - c) ** 2)\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 1\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "                'hidden_layers': hidden_layers,\n",
    "                'input_dim': input_dim,\n",
    "                'output_dim': output_dim,\n",
    "                'activation_fn_type': 'rbf',\n",
    "                'activation_fn_params': 'c=0, alpha=1',\n",
    "                'activation_fn': h}\n",
    "# set random state to make the experiments replicable\n",
    "rand_state = 127\n",
    "random = np.random.RandomState(rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.title('Data from the paper')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nn = Model.create(submodel_type=\"Feedforward\", architecture=architecture)\n",
    "my_subspace = Subspace.create(subspace_type=\"random\", model=my_nn, n_subspace=2)\n",
    "my_subspace.collect_vector(X=x, y=y)\n",
    "P, w = my_subspace.get_space()\n",
    "my_inference = Inference.create(inference_type=\"HMC\", model=my_nn, P=P, w_hat=w)\n",
    "# my_inference = Inference.create(inference_type=\"BBB\", model=my_nn, P=P, w_hat=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound 346.63368004153597; gradient mag: 922.7651717672312\n",
      "Iteration 100 lower bound 195.22009224300444; gradient mag: 417.619792247884\n",
      "Iteration 200 lower bound 137.45046392571888; gradient mag: 226.84888453436\n",
      "Iteration 300 lower bound 114.74074161539443; gradient mag: 124.16169113155686\n",
      "Iteration 400 lower bound 105.52134922138134; gradient mag: 71.21622234862728\n",
      "Iteration 500 lower bound 101.23821149973587; gradient mag: 47.190068446816746\n",
      "Iteration 600 lower bound 98.76737682575583; gradient mag: 36.27749198954713\n",
      "Iteration 700 lower bound 97.05576335434515; gradient mag: 29.774428430304713\n",
      "Iteration 800 lower bound 95.71597544654082; gradient mag: 24.876678953752617\n",
      "Iteration 900 lower bound 94.56053908767345; gradient mag: 20.988474889540583\n",
      "Iteration 1000 lower bound 93.51846194338967; gradient mag: 17.914792052033714\n",
      "Iteration 1100 lower bound 92.64578376718416; gradient mag: 15.3203374620375\n",
      "Iteration 1200 lower bound 92.01095544458073; gradient mag: 12.915183711618361\n",
      "Iteration 1300 lower bound 91.58676872886561; gradient mag: 10.744279624722603\n",
      "Iteration 1400 lower bound 91.30539848202899; gradient mag: 8.927377286559452\n",
      "Iteration 1500 lower bound 91.11307286286808; gradient mag: 7.478760376444326\n",
      "Iteration 1600 lower bound 90.97611094384342; gradient mag: 6.342380736274951\n",
      "Iteration 1700 lower bound 90.87445990236009; gradient mag: 5.446586022134375\n",
      "Iteration 1800 lower bound 90.79617723286668; gradient mag: 4.7295616078721885\n",
      "Iteration 1900 lower bound 90.7340011116567; gradient mag: 4.1452748330494\n",
      "Iteration 2000 lower bound 90.68336911386615; gradient mag: 3.6613593520969676\n",
      "Iteration 2100 lower bound 90.64130613830207; gradient mag: 3.255193990691855\n",
      "Iteration 2200 lower bound 90.6058021813576; gradient mag: 2.910598819144649\n",
      "Iteration 2300 lower bound 90.57545623707415; gradient mag: 2.615607571328161\n",
      "Iteration 2400 lower bound 90.54926386661052; gradient mag: 2.3610893158056534\n",
      "Iteration 2500 lower bound 90.52648462791291; gradient mag: 2.139905745794695\n",
      "Iteration 2600 lower bound 90.50655659919272; gradient mag: 1.9463813358031041\n",
      "Iteration 2700 lower bound 90.48904057762668; gradient mag: 1.7759569235245485\n",
      "Iteration 2800 lower bound 90.47358379270352; gradient mag: 1.6249533957938225\n",
      "Iteration 2900 lower bound 90.45989647996633; gradient mag: 1.4904005738396862\n",
      "Iteration 3000 lower bound 90.44773666592502; gradient mag: 1.3699028993335074\n",
      "Iteration 3100 lower bound 90.43689997717846; gradient mag: 1.2615262560331924\n",
      "Iteration 3200 lower bound 90.42721245084644; gradient mag: 1.1637001269328913\n",
      "Iteration 3300 lower bound 90.41852517514914; gradient mag: 1.075134906113515\n",
      "Iteration 3400 lower bound 90.41071012401497; gradient mag: 0.9947554851667886\n",
      "Iteration 3500 lower bound 90.403656837547; gradient mag: 0.9216509026288866\n",
      "Iteration 3600 lower bound 90.39726973912826; gradient mag: 0.8550379764512306\n",
      "Iteration 3700 lower bound 90.39146594692592; gradient mag: 0.7942357343390056\n",
      "Iteration 3800 lower bound 90.38617347473024; gradient mag: 0.7386473809344942\n",
      "Iteration 3900 lower bound 90.381329741754; gradient mag: 0.6877471458688329\n",
      "Iteration 4000 lower bound 90.37688032901893; gradient mag: 0.6410701762395932\n",
      "Iteration 4100 lower bound 90.37277793338966; gradient mag: 0.5982043566805845\n",
      "Iteration 4200 lower bound 90.368981480459; gradient mag: 0.5587834409352396\n",
      "Iteration 4300 lower bound 90.3654553653181; gradient mag: 0.5224811713930099\n",
      "Iteration 4400 lower bound 90.36216879645877; gradient mag: 0.489006209283934\n",
      "Iteration 4500 lower bound 90.35909522309417; gradient mag: 0.4580977611735416\n",
      "Iteration 4600 lower bound 90.35621183031454; gradient mag: 0.4295218115979055\n",
      "Iteration 4700 lower bound 90.3534990898729; gradient mag: 0.4030678820629258\n",
      "Iteration 4800 lower bound 90.35094035713635; gradient mag: 0.3785462443899007\n",
      "Iteration 4900 lower bound 90.34852150691681; gradient mag: 0.3557855251487088\n"
     ]
    }
   ],
   "source": [
    "params = {'step_size': 1e-3,\n",
    "              'max_iteration': 5000,\n",
    "              'random_restarts': 1}\n",
    "\n",
    "# fit my neural network to minimize MSE on the given data\n",
    "my_nn.fit(x_train=x.reshape((1, -1)), y_train=y.reshape((1, -1)), params=params)\n",
    "\n",
    "# get initial weights (in subspace dimension!!)\n",
    "position_init = my_nn.get_z_from_W(weights=my_nn.weights, P=P, w_hat=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential energy change: 49.4250245539962 49.468347072872135\n",
      "kinetic energy change: 2.454583318673124 2.7389834991682305\n",
      "total energy change: 51.879607872669325 52.20733057204036\n",
      "\n",
      "\n",
      "\n",
      "potential energy change: 51.176596627017936 51.0232649834071\n",
      "kinetic energy change: 5.881175731176554 4.305369588093772\n",
      "total energy change: 57.05777235819449 55.32863457150087\n",
      "\n",
      "\n",
      "\n",
      "potential energy change: 50.612549876223625 50.127693609817456\n",
      "kinetic energy change: 3.4928589018300205 4.428207919529215\n",
      "total energy change: 54.10540877805364 54.55590152934667\n",
      "\n",
      "\n",
      "\n",
      "potential energy change: 50.52166806108143 50.284571503789095\n",
      "kinetic energy change: 2.7664569384672006 2.6163857947251006\n",
      "total energy change: 53.28812499954863 52.90095729851419\n",
      "\n",
      "\n",
      "\n",
      "potential energy change: 51.02031132832864 51.30453312029257\n",
      "kinetic energy change: 4.433994785236476 3.452367402285587\n",
      "total energy change: 55.45430611356512 54.75690052257816\n",
      "\n",
      "\n",
      "\n",
      "potential energy change: 48.41637890931479 48.39769894143801\n",
      "kinetic energy change: 2.0642183835529275 5.028846976175016\n",
      "total energy change: 50.480597292867714 53.426545917613026\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_inference.train(X=x, y=y, warm_start=False, position_init=position_init,diagnostic_mode=True, step_size=1e-2, leapfrog_steps=1000,\n",
    "              total_samples=10000, burn_in=0.1, thinning_factor=2, check_point=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get posterior z\n",
    "n_sample = 10\n",
    "post_sample = my_inference.get_posterior(n_samples=n_sample).reshape(-1, 2)\n",
    "x_test = np.linspace(-8, 8, 100)\n",
    "y_test = np.reshape(\n",
    "    [my_nn.forward(P=P, w_hat=w, z=post_sample[i], X=x_test.reshape(1, -1)) for i in range(n_sample)],\n",
    "    (n_sample, -1)) \\\n",
    "         + np.random.normal(0, my_nn.Sigma_Y_det ** 0.5, size=(n_sample, len(x_test)))\n",
    "# because here Sigma_Y is 1-D, so determinants=its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid()\n",
    "plt.title('Posterior Predictive of Bayesian NN |HMC')\n",
    "# plt.ylim(-15, 15)\n",
    "for i in range(n_sample):\n",
    "    plt.plot(x_test, y_test[i], color='red', alpha=max(1 / n_sample, 0.1))\n",
    "plt.scatter(x, y, color='black', label='data')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x, y, color='black')\n",
    "plt.plot(x_test, y_test.mean(0), color='red', label='posterior predictive mean')\n",
    "plt.fill_between(x_test, np.percentile(y_test, 0.25, axis=0), np.percentile(y_test, 97.5, axis=0),\n",
    "                 color='red', label='95% CI', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Posterior Predictive of Bayesian NN with 95% CI|HMC')\n",
    "plt.grid()\n",
    "# plt.ylim(-15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
